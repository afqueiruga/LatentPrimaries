Machine Determination of Better Representations of Multiphase Equation of States for Subsurface Flow Simulation

The biggest challenge in simulation of subsurface flows is the representation of complex multiphase and multicomponent fluids (and solids.)
The equation of state (EOS) is usually treated as sets of empirical fits broken up according to phases, derived and fit by scientists guided by thermodynamic theory.
The descriptions become combinatorially more complex as species and phases are added, resulting in combinatorially more human labor and combinatorially more code consisting of branching logic.
Numerically solving these descriptions becomes challenging due to the phase switching and primary variable switching logic needed and is the primary bottleneck to simulation performance.

In this methodology, we step away from the traditional approaches and redescribe our problem as a differential algebraic equation with a constraint: the balances of mass and energy are constrained by the EOS.
Because the EOS was originally derived from data, a data-driven approach lends itself in which the EOS is a set of points in temperature-pressure-density-enthalpy space. (In the multicomponent cases there are more dimensions.)
We train an autoencoder to determine the lower-dimensional representation of the EOS surface using modern deep learning techniques without using any phase labels. The decoder end of the model is then plugged back into the balance laws, eliminating the constrain equation.
The simulation unknowns are now variables on the latent space of the autoencoder (the inputs of the decoder), which can be solved in a straight forward manner with Newton's method and no phase-switching logic.
This provides a more robust numerical algorithm, while putting the onus of programming part of the simulation itself onto the computer: tens of thousands of lines of human written code consisting of empirical fits and branching logic are replaced by code generated by the learned model.

We demonstrate this approach to solving constrained differential equations on the pendulum, before demonstrating two EOSes of water: one with just liquid-gas phases, and one with liquid-gas-ice-supercritical regimes. The notion of phases does not appear in this multiphase simulation. We show a model architecture that is able to learn phase labels in the unsupervised autoencoder training process, such human-scientist interpretable results are obtained from the machine learning process. We compare this and other model architectures, including common deep neural networks, based on autoencoder error and simulation success metrics. We stress that the presented approach is only utilizing machine learning on material relations derived from empirical data: the simulation is indeed solving physical balance laws.




---more copy
The points only contain the intensive properties that appear in the balance laws; they are not labeled by phase IDs or phase-mixture saturations.


--short copy:

The equation of state (EOS) is usually treated as sets of empirical fits broken up according to phases, derived and fit by scientists guided by thermodynamic theory.


Representing complex physical systems with multiple speicies, phases, chemical reactions, and heterogenous scale effects poses an intractability problem to modeling. How do we analyze complex experimental data and ab initio simulations and derive new macroscale relations to describe the systems? Simply a single material with multiple phase transitions is a challenge, and the descriptions become combinatorially more complex as species and phases are added, resulting in combinatorially more human labor and combinatorially more code consisting of branching logic. The descriptions then pose numerical challenges when incorporated into macroscale simulations due to crutches such as discrete phase state machines and primary variable switching.

Our proposed approach is to build upon modern machine learning techniques to aid in equation discovery. An autoencoder is trained on the original material dataset to learn a lower-dimensional representation of the underlying manifold. The model is designed to be directly incorporated into a macroscale simulation of physical balance laws, where now the traditional partial differential equations are being solved on the learned latent space. This provides a more robust numerical algorithm, while putting the onus of programming part of the simulation itself onto the computer: tens of thousands of lines of human written code consisting of empirical fits and branching logic are replaced by code generated by the learned model. The methodology will first be demonstrated on datasets based on thermodynamic intensive variables, which are already challenging to analyze, before being extended to richer datasets such as experimental images or molecular dynamics. We stress that the proposed approach is only utilizing machine learning on material data: the simulation is indeed solving physical balance laws. Through deep learning approaches combined with domain-specific goals, we can learn feature sets that are both interpretable and directly apply to analyzing larger systems. 
